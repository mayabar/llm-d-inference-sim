apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllm
  labels:
    app: vllm
spec:
  replicas: 1
  selector:
    matchLabels:
      app: vllm
  template:
    metadata:
      labels:
        app: vllm
    spec:
      containers:
        - name: vllm
          image: ghcr.io/llm-d/llm-d-cuda:v0.3.1
          command:
            - /bin/sh
            - -c
          args:
            - |
              vllm serve Qwen/Qwen3-0.6B \
              --host 0.0.0.0 \
              --port 8000 \
              --block-size 16 \
              --prefix-caching-hash-algo sha256_cbor \
              --kv-transfer-config '{"kv_connector":"NixlConnector", "kv_role":"kv_both"}' \
              --kv-events-config "{\"enable_kv_cache_events\":true,\"publisher\":\"zmq\",\"endpoint\":\"tcp://zmq-listener-service:5557\",\"topic\":\"kv@${POD_IP}@Qwen/Qwen3-0.6B\"}"
          env:
          - name: NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: PYTHONHASHSEED
            value: "42"
          - name: POD_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.podIP
          - name: CUDA_VISIBLE_DEVICES
            value: "0"
          - name: UCX_TLS
            value: cuda_ipc,cuda_copy,tcp
          - name: VLLM_NIXL_SIDE_CHANNEL_HOST
            valueFrom:
              fieldRef:
                fieldPath: status.podIP
          - name: VLLM_NIXL_SIDE_CHANNEL_PORT
            value: "5557"
          - name: VLLM_LOGGING_LEVEL
            value: DEBUG
          - name: DP_SIZE
            value: "1"
          - name: TP_SIZE
            value: "1"
          - name: DP_SIZE_LOCAL
            value: "1"
          
          - name: HF_HOME
            value: /model-cache
          # - name: HF_TOKEN
          #   valueFrom:
          #     secretKeyRef:
          #       name: llm-d-hf-token
          #       key: HF_TOKEN
          ports:
          - containerPort: 5557
            protocol: TCP
          - containerPort: 8000
            name: metrics
            protocol: TCP
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /health
              port: 8000
            periodSeconds: 10
            timeoutSeconds: 15
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /v1/models
              port: 8000
            periodSeconds: 5
            timeoutSeconds: 2
          startupProbe:
            failureThreshold: 60
            httpGet:
              path: /v1/models
              port: 8000
            initialDelaySeconds: 15
            periodSeconds: 30
            timeoutSeconds: 5
          
          resources:
            limits:
              nvidia.com/gpu: "1"
            requests:
              nvidia.com/gpu: "1"
          
          volumeMounts:
            - mountPath: /.config
              name: metrics-volume
            - mountPath: /.cache
              name: torch-compile-cache
            - name: model-storage
              mountPath: /model-cache

      volumes:
        - emptyDir: {}
          name: metrics-volume
        - emptyDir: {}
          name: torch-compile-cache
        - name: model-storage
          emptyDir:
            sizeLimit: 20Gi
